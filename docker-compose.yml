# ============================================================================
# HYBRID MICROSERVICES ARCHITECTURE REFERENCE
# ============================================================================
# 
# IMPORTANT: This docker-compose.yml file is NOT used for actual deployment.
# It serves as documentation for the service definitions.
#
# ACTUAL DEPLOYMENT APPROACH:
# - config-server: Runs LOCALLY as JAR (port 8888)
# - All other services: Run as DOCKER CONTAINERS with individual Dockerfiles
# - Orchestration: Uses ./start-services-new.sh script
# - Observability: Loki, Alloy, Alloy (Phase 1), Tempo, Prometheus, Grafana via scripts
# - Customer Analytics: Alloy-based banking intelligence engine (ports 12346-12347)
#
# ============================================================================

services:
  # config-server:
  #   NOTE: config-server runs LOCALLY as JAR, not in Docker
  #   Started via: scripts/microservices.sh -> start_local_service()
  #   Port: 8888
  #   Purpose: Provides centralized configuration to other services
  #   build:
  #     context: .
  #     dockerfile: config-server/Dockerfile
  #   ports:
  #     - "8888:8888"
  #   environment:
  #     - SPRING_PROFILES_ACTIVE=dev
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:8888/actuator/health"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5
  #   networks:
  #     - msnet

  # ============================================================================
  # MICROSERVICES - Docker Container Deployment
  # ============================================================================
  # NOTE: These services are deployed via individual Docker builds, not this compose file
  # Actual deployment: scripts/microservices.sh -> start_docker_service()
  # Each service uses its own Dockerfile with OpenTelemetry integration
  # Logging labels: "logging=alloy" and "service=${service_name}" for Alloy log discovery
  # ============================================================================

  accounts:
    # DEPLOYED VIA: docker build -t accounts-service:latest ./accounts
    # LABELS: logging=alloy, service=accounts (for Alloy log discovery)
    # OTEL: Integrated with traces sent to otel-collector-service:4318
    build:
      context: ./accounts
      dockerfile: Dockerfile
    ports:
      - "8081:8081"
    environment:
      - SPRING_PROFILES_ACTIVE=dev
      - SPRING_CONFIG_IMPORT=optional:configserver:http://host.docker.internal:8888
    labels:
      - logging=alloy
      - service=accounts
    # depends_on:
    #   - config-server
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - msnet

  cards:
    build:
      context: ./cards
      dockerfile: Dockerfile
    ports:
      - "8082:8082"
    environment:
      - SPRING_PROFILES_ACTIVE=dev
      - SPRING_CONFIG_IMPORT=optional:configserver:http://host.docker.internal:8888
    labels:
      - logging=alloy
      - service=cards
    # depends_on:
    #   - config-server
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8082/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - msnet

  loans:
    build:
      context: ./loans
      dockerfile: Dockerfile
    ports:
      - "8083:8083"
    environment:
      - SPRING_PROFILES_ACTIVE=dev
      - SPRING_CONFIG_IMPORT=optional:configserver:http://host.docker.internal:8888
    labels:
      - logging=alloy
      - service=loans
    # depends_on:
    #   - config-server
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - msnet

  customer:
    # DEPLOYED VIA: docker build -t customers-service:latest ./customers  
    # LABELS: logging=alloy, service=customers (for Alloy log discovery)
    # OTEL: Integrated with traces sent to otel-collector-service:4318
    build:
      context: ./customer
      dockerfile: Dockerfile
    ports:
      - "8084:8084"
    environment:
      - SPRING_PROFILES_ACTIVE=dev
      - SPRING_CONFIG_IMPORT=optional:configserver:http://host.docker.internal:8888
    labels:
      - logging=alloy
      - service=customers
    # depends_on:
    #   - config-server
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8084/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - msnet

  otel-collector:
    # NOTE: This OTEL Collector definition is also NOT used
    # DEPLOYED VIA: scripts/observability.sh -> start_otel_collector()
    # Actual deployment uses individual Docker build approach
    image: otel/opentelemetry-collector:0.109.0
    container_name: otel-collector
    volumes:
      - ./otel-collector/collector-config.yaml:/etc/otelcol/config.yaml:ro
    command: ["--config", "/etc/otelcol/config.yaml"]
    ports:
      - "4317:4317" # OTLP gRPC
      - "4318:4318" # OTLP HTTP
    healthcheck:
      test: ["CMD", "wget", "-qO", "-", "http://localhost:13133/healthz"]
      interval: 30s
      timeout: 5s
      retries: 5
    networks:
      - msnet


networks:
  msnet:
    driver: bridge

# ============================================================================
# ACTUAL DEPLOYMENT ARCHITECTURE SUMMARY
# ============================================================================
#
# LOCAL SERVICES (JAR deployment):
# ├── config-server:8888      → Central configuration
#
# DOCKER SERVICES (Container deployment):
# ├── eureka-server:8761       → Service discovery  
# ├── accounts:8081           → Account management
# ├── cards:8082              → Card management  
# ├── loans:8083              → Loan management
# ├── customers:8084          → Customer management
# └── gateway-server:8072     → API gateway
#
# OBSERVABILITY STACK (Container deployment):
# ├── otel-collector:4317/4318 → Trace collection
# ├── tempo:3200               → Trace storage
# ├── loki:3100               → Log aggregation  
# ├── alloy:12345             → Unified observability (fully replaced Promtail)
# ├── prometheus:9090         → Metrics collection
# └── grafana:3000            → Visualization
#
# DEPLOYMENT COMMANDS:
# - Start: ./start-services-new.sh
# - Stop:  ./stop-services.sh
#
# ============================================================================

